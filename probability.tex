\documentclass[11pt]{article}
\renewcommand{\baselinestretch}{1.05}
\usepackage{amsmath,amsthm,verbatim,amssymb,amsfonts,amscd,graphicx,mathtools}
\usepackage{graphics}
\usepackage{graphicx}
\usepackage{color}
\usepackage{pgfplots}
\usepackage{csquotes}
\usepackage{fancyvrb}
\usepackage{wrapfig}
\usepackage{centernot}
\usepackage{pifont}
\usepackage{hyperref}
\topmargin0.0cm \headheight0.0cm
\headsep0.0cm
\oddsidemargin0.0cm
\textheight23.0cm
\textwidth16.5cm
\footskip1.0cm
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}
\newtheorem{corollary}{Corollary}
\newtheorem{lemma}{Lemma}
\newtheorem{proposition}{Proposition}
\newtheorem*{surfacecor}{Corollary 1}
\newtheorem{conjecture}{Conjecture} 
\newtheorem{question}{Question} 
\theoremstyle{definition}
\newtheorem{definition}{Definition}

\newenvironment{packed_enum}{
\begin{enumerate}
  \setlength{\itemsep}{1pt}
  \setlength{\parskip}{0pt}
  \setlength{\parsep}{0pt}
}{\end{enumerate}}

\newenvironment{packed_items}{
\begin{itemize}
  \setlength{\itemsep}{1pt}
  \setlength{\parskip}{0pt}
  \setlength{\parsep}{0pt}
}{\end{itemize}}

\begin{document}

\section*{5. Discrete Probability}

In probability theory, the goal is to determine how likely something is to
happen, when studying phenomena that are unpredictable. An
\begin{em}experiment\end{em} here means any controlled, physical action that
can be repeated an arbitrary number of times. Experiments for which there is 
more than one possible result are said to be \begin{em}probabilistic\end{em}---or simply 
\begin{em}random\end{em}. The degree of certainty associated with the result of 
a random experiment is then what we refer to as ``probability.'' 

\subsection*{Sample spaces}

\noindent
A distinct observation that results from a random experiment is called an
\begin{em}outcome\end{em}, and a \begin{em}sample space\end{em} is the
collection of all possible outcomes of such an experiment. (The sample space is
sometimes also called a \begin{em}universe\end{em}.) When an experiment is 
executed once and an outcome is observed, this is known as a \begin{em}trial\end{em}.

\subsubsection*{Examples:}

Many examples of probabilistic experiments are found in games of chance. For a 
roll of a single, six-sided die, the sample space may be defined as the set
\begin{displaymath}
	\Omega = \{ 1, 2, 3, 4, 5, 6 \}.
\end{displaymath}

\noindent Similarly, a coin flip has only two possible outcomes, and is characterized by a sample space
\begin{displaymath}
  \{ \text{Head}, \text{Tails} \} \text{, which can also be encoded as the set } \{ 0, 1 \}.
\end{displaymath}

\noindent Flipping a coin $ n $ times creates a sample space $ \{0, 1\}^n $,
which is the set of all binary $ n $-strings. A sample space can, unlike these
examples, be infinite. Discrete probability theory, however, only deals with 
finite and countably infinite sample spaces.

\subsection*{Probability distributions}

Each outcome in a sample space is associated with a probability, or
\begin{em}weight\end{em}, denoted by a real number in the range $0$ to $1$ (both
  inclusive), which represents its likelihood to occur. A \begin{em}probability distribution\end{em} (or probability measure) on a sample space $\Omega$ is a function $P : \Omega \rightarrow [0, 1]$. An important requirement here is that the sum of all probabilities in the sample space must be equal to $ 1 $.
\begin{displaymath}
  \text{If $ \Omega $ is a sample space, then } \sum_{i \in \Omega} P(i) = 1.
\end{displaymath}

\noindent We can also think of the probability of an outcome as the proportion of times that it occurs in a random experiment, when the experiment is repeated a sufficiently large number of times. If $ C_i(n) $ denotes the the number of occurences of $ i $ observed when sampling at random $ n $ times from a probability distribution $ P $, then

\begin{displaymath}
  \displaystyle P(i) = \lim_{n\to \infty} \frac{C_i(n)}{n} .
\end{displaymath}

\subsubsection*{The uniform distribution}

\noindent If we assume a fair die in our first example, we obtain a distribution which is said to be \begin{em}uniform\end{em}:

\bgroup
\def\arraystretch{1.3}
\begin{center}
\begin{tabular}{c | c c c c c c}
	$i$ & 1 & 2 & 3 & 4 & 5 & 6 \\
	\hline
	$P(i)$ & $\frac{1}{6}$ & $\frac{1}{6}$ & $\frac{1}{6}$ & $\frac{1}{6}$ & $\frac{1}{6}$ & $\frac{1}{6}$
\end{tabular}
\end{center}
\egroup

\noindent A uniform probability distribution is one that satisfies the property

\begin{displaymath}
	\forall i \in \Omega\left[ P(i) = \frac{1}{|\Omega|} \right].
\end{displaymath}

\subsubsection*{Bernoulli distribution}

TODO

\subsubsection*{Point distribution}

TODO

\subsection*{Events}

An \begin{em}event\end{em} is simply a subset of a sample space. If $S$ is an event defined on the sample space $\Omega$, then
\begin{displaymath}
	S \subseteq \Omega.
\end{displaymath}

\noindent For some concrete examples, we can think of a lottery with exactly one
winner, and the following set of participants (i.e., the sample space)

\begin{displaymath}
  \{ \text{Angela, Donald, Justin, Kim, Robert, Stefan, Theresa} \}.
\end{displaymath}

\noindent Then, the event

\begin{packed_enum}
\item of the winner being male is $ \{ \text{Donald, Justin, Kim, Robert, Stefan} \} $, 
\item that the winner's name contains the letter `E' is $ \{ \text{Angela, Robert, Stefan, Theresa} \} $,
\item that the winner is Justin is $ \{ \text{Justin} \} $, and
\item that the winner is \begin{bf}not\end{bf} Justin is $ \{ \text{Angela, Donald, Kim, Robert, Stefan, Theresa} \} $.
\end{packed_enum} 

(TO BE CONTINUED)

\end{document}

